# Pipeline Completa ETL - Kritikos

## Overview

Esta documentaÃ§Ã£o descreve a pipeline completa de coleta de dados da CÃ¢mara dos Deputados implementada para o projeto Kritikos. A pipeline foi desenvolvida como parte da issue **ETL-01: Coleta de Dados da API da CÃ¢mara**.

## ğŸ—ï¸ Arquitetura da Pipeline

### Componentes Principais

1. **Coleta de ReferÃªncia** (`coleta_referencia.py`)
   - Deputados e seus dados pessoais
   - Partidos polÃ­ticos
   - Gastos parlamentares
   - Mandatos e legislaturas

2. **Coleta de ProposiÃ§Ãµes** (`coleta_proposicoes.py`)
   - ProposiÃ§Ãµes de alto impacto (PEC, PL, PLP, MPV)
   - Autores e relacionamentos
   - Armazenamento no Google Cloud Storage

3. **Coleta de FrequÃªncia** (`coleta_frequencia.py`)
   - Dados reais de presenÃ§a em sessÃµes
   - Dias trabalhados, faltas justificadas/nÃ£o justificadas
   - Rankings mensais de frequÃªncia

4. **Coleta de Emendas** (`coleta_emendas.py`)
   - Emendas orÃ§amentÃ¡rias
   - Relacionamento com deputados
   - Armazenamento completo no GCS

## ğŸ“ Estrutura de Arquivos

```
backend/
â”œâ”€â”€ executar_pipeline_completa.py    # Script principal de execuÃ§Ã£o
â”œâ”€â”€ testar_pipeline_completa.py      # Script de testes
â”œâ”€â”€ README_PIPELINE_ETL.md           # Esta documentaÃ§Ã£o
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ etl/
â”‚   â”‚   â”œâ”€â”€ coleta_referencia.py     # Coleta de dados de referÃªncia
â”‚   â”‚   â”œâ”€â”€ coleta_proposicoes.py    # Coleta de proposiÃ§Ãµes
â”‚   â”‚   â”œâ”€â”€ coleta_frequencia.py     # Coleta de frequÃªncia
â”‚   â”‚   â”œâ”€â”€ coleta_emendas.py        # Coleta de emendas
â”‚   â”‚   â”œâ”€â”€ config.py                # ConfiguraÃ§Ãµes centralizadas
â”‚   â”‚   â””â”€â”€ cache_utils.py           # Sistema de cache
â”‚   â”œâ”€â”€ models/                      # Modelos SQLAlchemy
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ gcs_utils.py             # Google Cloud Storage
â”‚       â””â”€â”€ db_utils.py              # UtilitÃ¡rios de banco
â””â”€â”€ testes/                          # Scripts de teste e manutenÃ§Ã£o
    â””â”€â”€ scripts_manutencao/
```

## ğŸš€ ExecuÃ§Ã£o da Pipeline

### PrÃ©-requisitos

1. **Python 3.8+**
2. **Banco de dados PostgreSQL** configurado
3. **Google Cloud Storage** (opcional, mas recomendado)
4. **VariÃ¡veis de ambiente** configuradas

### VariÃ¡veis de Ambiente

```bash
# Banco de dados
DATABASE_URL=postgresql://user:password@localhost:5432/kritikos

# Google Cloud Storage
GCS_BUCKET_NAME=kritikos-emendas-prod
GCS_PROJECT_ID=kritikos-474618
GOOGLE_APPLICATION_CREDENTIALS=./service-account-key.json
```

### ExecuÃ§Ã£o

#### 1. Testar Componentes

```bash
cd backend
python testar_pipeline_completa.py
```

#### 2. Executar Pipeline Completa

```bash
cd backend
python executar_pipeline_completa.py
```

#### 3. Executar Componentes Individualmente

```bash
# Coleta de referÃªncia
python src/etl/coleta_referencia.py

# Coleta de proposiÃ§Ãµes
python src/etl/coleta_proposicoes.py

# Coleta de frequÃªncia
python src/etl/coleta_frequencia.py

# Coleta de emendas
python src/etl/coleta_emendas.py
```

## âš™ï¸ ConfiguraÃ§Ãµes

### ConfiguraÃ§Ãµes Principais (`src/etl/config.py`)

```python
# Limites de coleta
HACKATHON_CONFIG = {
    'deputados': {
        'limite_total': 9999,  # Todos os deputados
        'apenas_em_exercicio': True
    },
    'proposicoes': {
        'tipos_para_coletar': ['PEC', 'PL', 'PLP', 'MPV', 'PDC', 'PLV'],
        'limite_total': 500,
        'prioridade_tipos': {
            'PEC': 1,  # Maior prioridade
            'PL': 2,
            'PLP': 3,
            'MPV': 4,
            'PDC': 5,
            'PLV': 6
        }
    }
}

# ConfiguraÃ§Ãµes da API
API_CONFIG = {
    'base_url': 'https://dadosabertos.camara.leg.br/api/v2',
    'rate_limit_delay': 0.3,  # segundos entre requisiÃ§Ãµes
    'timeout': 15,
    'max_retries': 3
}
```

## ğŸ“Š Dados Coletados

### 1. Deputados

- **Dados pessoais**: nome, CPF, data de nascimento, escolaridade
- **Dados polÃ­ticos**: partido, estado, mandato, situaÃ§Ã£o
- **Gastos**: despesas parlamentares detalhadas
- **FrequÃªncia**: presenÃ§a em sessÃµes, faltas, rankings

### 2. ProposiÃ§Ãµes

- **Tipos priorizados**: PEC, PL, PLP, MPV, PDC, PLV
- **Dados bÃ¡sicos**: ementa, nÃºmero, ano, situaÃ§Ã£o
- **Dados completos**: texto integral, tramitaÃ§Ã£o, votaÃ§Ãµes
- **Autores**: relacionamento com deputados
- **Armazenamento**: dados completos no GCS

### 3. FrequÃªncia

- **Dados reais**: baseados em presenÃ§a confirmada em sessÃµes
- **MÃ©tricas**: dias trabalhados, faltas justificadas/nÃ£o justificadas
- **Rankings**: posicionamento mensal dos deputados
- **Detalhes**: sessÃµes especÃ­ficas, duraÃ§Ã£o, tipo

### 4. Emendas

- **Dados orÃ§amentÃ¡rios**: valores, beneficiÃ¡rios, programas
- **Relacionamentos**: deputados autores, proposiÃ§Ãµes relacionadas
- **Armazenamento**: dados completos no GCS

## ğŸ”§ Funcionalidades AvanÃ§adas

### Sistema de Cache

- **Cache local**: reduz chamadas Ã  API
- **TTL configurÃ¡vel**: 6 horas padrÃ£o
- **Cache por endpoint**: diferentes tempos por tipo de dado

### DeduplicaÃ§Ã£o

- **EstratÃ©gia composite key**: evita duplicados
- **UPSERT automÃ¡tico**: atualiza registros existentes
- **VerificaÃ§Ã£o por mÃºltiplos campos**: ID da API, CPF, etc.

### Google Cloud Storage

- **CompressÃ£o gzip**: reduz custos de armazenamento
- **Estrutura organizada**: por tipo e ano
- **URLs pÃºblicas**: acesso direto aos dados
- **Metadados**: controle de versÃ£o e integridade

### Tratamento de Erros

- **Retry automÃ¡tico**: atÃ© 3 tentativas
- **Logging detalhado**: erros e warnings
- **RecuperaÃ§Ã£o graceful**: continua mesmo com falhas parciais
- **Rollback automÃ¡tico**: em caso de erro crÃ­tico

## ğŸ“ˆ Monitoramento e Logs

### Logs de ExecuÃ§Ã£o

```
ğŸš€ INICIANDO PIPELINE COMPLETA DE COLETA
============================================================
ğŸ“… InÃ­cio: 19/10/2025 18:00:00
ğŸ”§ Ambiente: 2025

==================== Coleta de ReferÃªncia ====================
â±ï¸ Iniciando Coleta de ReferÃªncia em 18:00:01
ğŸ›ï¸ Coletando partidos...
   ğŸ“Š Processando lote de 25 partidos...
      âœ… Inserido: PL - Partido Liberal
      âœ… Inserido: PT - Partido dos Trabalhadores
      ...
âœ… Coleta de ReferÃªncia concluÃ­da em 45.2s
```

### MÃ©tricas Coletadas

- **Total de registros**: por tipo de dado
- **Taxa de sucesso**: percentual de coleta concluÃ­da
- **Performance**: tempo por etapa
- **Erros**: quantidade e tipo

## ğŸ› ï¸ ManutenÃ§Ã£o

### Scripts de ManutenÃ§Ã£o

Localizados em `testes/scripts_manutencao/`:

- `limpar_banco.py`: limpeza de dados
- `verificar_dados.py`: validaÃ§Ã£o de integridade
- `corrigir_ids_negativos.py`: correÃ§Ã£o de problemas
- `remover_bancada_amapa.py`: limpezas especÃ­ficas

### Backup e RecuperaÃ§Ã£o

1. **Backup do banco**: regularmente automatizado
2. **Backup GCS**: dados importantes na nuvem
3. **Logs de execuÃ§Ã£o**: histÃ³rico de execuÃ§Ãµes
4. **Pontos de restauraÃ§Ã£o**: por data

## ğŸ” ValidaÃ§Ã£o de Dados

### Testes AutomÃ¡ticos

O script `testar_pipeline_completa.py` valida:

1. **ConexÃµes**: banco, GCS, API
2. **Coletores**: inicializaÃ§Ã£o e funcionamento bÃ¡sico
3. **IntegraÃ§Ã£o**: salvamento e relacionamentos
4. **Performance**: tempos de resposta

### ValidaÃ§Ã£o de Qualidade

- **Campos obrigatÃ³rios**: verificados no salvamento
- **Formatos de dados**: datas, nÃºmeros, textos
- **Integridade referencial**: relacionamentos entre tabelas
- **ConsistÃªncia**: valores lÃ³gicos e regras de negÃ³cio

## ğŸš€ Performance e OtimizaÃ§Ã£o

### OtimizaÃ§Ãµes Implementadas

1. **Batch processing**: processamento em lotes
2. **Cache inteligente**: reduz chamadas Ã  API
3. **ConexÃµes persistentes**: reuse de sessÃµes
4. **CompressÃ£o GCS**: reduz custos e tempo
5. **Rate limiting**: respeita limites da API

### MÃ©tricas de Performance

- **Coleta completa**: ~30-45 minutos
- **Throughput**: ~100 registros/segundo
- **Taxa de erro**: <1% em condiÃ§Ãµes normais
- **Uso de memÃ³ria**: <500MB pico

## ğŸ”„ Agendamento

### ExecuÃ§Ã£o Automatizada

RecomendaÃ§Ãµes de agendamento:

```bash
# DiÃ¡rio (para dados em tempo real)
0 2 * * * cd /path/to/backend && python executar_pipeline_completa.py

# Semanal (para dados histÃ³ricos)
0 3 * * 0 cd /path/to/backend && python executar_pipeline_completa.py
```

### ExecuÃ§Ã£o Manual

Para execuÃ§Ãµes sob demanda ou testes:

```bash
# Modo verbose
python executar_pipeline_completa.py --verbose

# Modo dry-run (apenas testes)
python executar_pipeline_completa.py --dry-run

# Componente especÃ­fico
python executar_pipeline_completa.py --componente proposicoes
```

## ğŸ› Troubleshooting

### Problemas Comuns

1. **Timeout da API**: aumentar `rate_limit_delay`
2. **Erro de conexÃ£o**: verificar `DATABASE_URL`
3. **GCS nÃ£o disponÃ­vel**: verificar credenciais
4. **MemÃ³ria insuficiente**: reduzir `batch_size`

### SoluÃ§Ãµes

```python
# Aumentar delay da API
API_CONFIG['rate_limit_delay'] = 0.5

# Reduzir batch size
API_CONFIG['batch_size'] = 25

# Desabilitar GCS temporariamente
GCS_CONFIG['enabled'] = False
```

## ğŸ“ Suporte

### Contato

- **Desenvolvimento**: equipe Kritikos
- **DocumentaÃ§Ã£o**: este README
- **Issues**: GitHub do projeto

### Recursos

- [API da CÃ¢mara dos Deputados](https://dadosabertos.camara.leg.br/)
- [Google Cloud Storage](https://cloud.google.com/storage)
- [SQLAlchemy](https://www.sqlalchemy.org/)

---

## ğŸ“ HistÃ³rico de MudanÃ§as

### v1.0.0 (2025-10-19)
- âœ… Pipeline completa implementada
- âœ… Coleta de dados reais de frequÃªncia
- âœ… IntegraÃ§Ã£o com Google Cloud Storage
- âœ… Sistema de testes automatizados
- âœ… DocumentaÃ§Ã£o completa

### PrÃ³ximas VersÃµes
- ğŸ”„ Dashboard de monitoramento
- ğŸ”„ Alertas automÃ¡ticos
- ğŸ”„ OtimizaÃ§Ãµes de performance
- ğŸ”„ Mais tipos de dados

---

**Status**: âœ… **PRODUÃ‡ÃƒO READY**

A pipeline estÃ¡ pronta para uso em produÃ§Ã£o com todos os componentes testados e validados.
