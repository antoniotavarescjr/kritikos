#!/usr/bin/env python3
"""
ETL Utils - Utilit√°rios Centralizados para Coletores
Elimina redund√¢ncias e padroniza opera√ß√µes comuns entre todos os coletores ETL

Autor: Kritikos Team
Data: Outubro/2025
"""

import requests
import time
from datetime import datetime
from typing import Optional, Dict, List, Any, Union
from sqlalchemy.orm import Session
from abc import ABC, abstractmethod
import hashlib
import json

# Importar utilit√°rios existentes
try:
    from ..utils.cache_utils import CacheManager, get_cache_manager
except ImportError:
    # Fallback para execu√ß√£o direta
    from utils.cache_utils import CacheManager, get_cache_manager

try:
    from ..utils.gcs_utils import get_gcs_manager
except ImportError:
    # Fallback para execu√ß√£o direta
    from utils.gcs_utils import get_gcs_manager

try:
    from .config import get_config
except ImportError:
    # Fallback para execu√ß√£o direta
    from etl.config import get_config


class ETLBase(ABC):
    """
    Classe base abstrata para todos os coletores ETL
    Fornece funcionalidades comuns e padronizadas
    """
    
    def __init__(self, config_name: str = None):
        """
        Inicializa o coletor base
        
        Args:
            config_name: Nome da configura√ß√£o espec√≠fica no config.py
        """
        self.config_name = config_name
        self.api_config = get_config('api')
        self.session = self._setup_session()
        self.cache = self._setup_cache()
        self.gcs_manager = get_gcs_manager()
        
        # Carregar configura√ß√µes espec√≠ficas se fornecido
        self.specific_config = {}
        if config_name:
            hackathon_config = get_config('hackathon')
            self.specific_config = hackathon_config.get(config_name, {})
        
        print(f"‚úÖ {self.__class__.__name__} inicializado")
        if config_name:
            print(f"   üìã Config: {config_name}")
    
    def _setup_session(self) -> requests.Session:
        """
        Configura sess√£o HTTP padr√£o com headers e timeout
        
        Returns:
            requests.Session: Sess√£o configurada
        """
        session = requests.Session()
        session.headers.update({
            'User-Agent': self.api_config['user_agent'],
            'Accept': 'application/json'
        })
        return session
    
    def _setup_cache(self) -> Optional[CacheManager]:
        """
        Setup do cache manager
        
        Returns:
            CacheManager: Inst√¢ncia do cache ou None
        """
        try:
            cache_dir = f"cache/{self.__class__.__name__.lower()}"
            return get_cache_manager(cache_dir=cache_dir, ttl_hours=6)
        except Exception as e:
            print(f"‚ö†Ô∏è Cache n√£o dispon√≠vel: {e}")
            return None
    
    def make_request(self, url: str, params: Optional[Dict] = None, use_cache: bool = True, timeout: int = None) -> Optional[Dict]:
        """
        M√©todo unificado para requisi√ß√µes HTTP com cache e rate limiting
        
        Args:
            url: URL da API
            params: Par√¢metros da requisi√ß√£o
            use_cache: Se deve usar cache
            timeout: Timeout personalizado
            
        Returns:
            Dict: Resposta da API ou None se erro
        """
        # Verificar cache primeiro
        if use_cache and self.cache:
            cache_key = f"{url}_{str(sorted(params.items()) if params else '')}"
            cached_data = self.cache.get(cache_key)
            if cached_data:
                print(f"      üì¶ Cache hit: {url}")
                return cached_data
        
        try:
            # Rate limiting
            time.sleep(self.api_config['rate_limit_delay'])
            
            # Fazer requisi√ß√£o
            response = self.session.get(
                url, 
                params=params, 
                timeout=timeout or self.api_config['timeout']
            )
            response.raise_for_status()
            
            data = response.json()
            
            # Salvar no cache
            if use_cache and self.cache and data:
                from datetime import timedelta
                self.cache.set(cache_key, data, ttl=timedelta(hours=2))
            
            return data
            
        except requests.exceptions.RequestException as e:
            print(f"‚ùå Erro na requisi√ß√£o {url}: {e}")
            return None
        except Exception as e:
            print(f"‚ùå Erro ao processar resposta: {e}")
            return None
    
    def paginated_request(self, endpoint: str, params: Optional[Dict] = None, max_pages: int = None, max_items: int = None) -> List[Dict]:
        """
        Requisi√ß√£o com pagina√ß√£o autom√°tica
        
        Args:
            endpoint: Endpoint da API
            params: Par√¢metros da requisi√ß√£o
            max_pages: N√∫mero m√°ximo de p√°ginas
            max_items: N√∫mero m√°ximo de itens
            
        Returns:
            List[Dict]: Lista de todos os itens retornados
        """
        all_items = []
        page = 1
        pages_processed = 0
        
        while True:
            # Adicionar p√°gina aos par√¢metros
            pag_params = params.copy() if params else {}
            pag_params['pagina'] = page
            pag_params['itens'] = pag_params.get('itens', 100)
            
            print(f"      üìÑ P√°gina {page}...")
            data = self.make_request(endpoint, pag_params, use_cache=False)
            
            if not data:
                break
            
            items = data.get('dados', [])
            if not items:
                print(f"      üìÑ P√°gina {page} vazia")
                break
            
            all_items.extend(items)
            pages_processed += 1
            
            print(f"      üìä P√°gina {page}: +{len(items)} itens (total: {len(all_items)})")
            
            # Verificar limites
            if max_pages and pages_processed >= max_pages:
                print(f"      ‚èπÔ∏è Limite de p√°ginas ({max_pages}) atingido")
                break
            
            if max_items and len(all_items) >= max_items:
                print(f"      ‚èπÔ∏è Limite de itens ({max_items}) atingido")
                break
            
            # Verificar pr√≥xima p√°gina
            links = {link['rel']: link['href'] for link in data.get('links', [])}
            if not links.get('next'):
                break
            
            page += 1
        
        return all_items


class DateParser:
    """Utilit√°rio centralizado para parsing de datas"""
    
    @staticmethod
    def parse_date(date_str: Optional[str]) -> Optional[datetime]:
        """
        Converte string de data para objeto datetime
        
        Args:
            date_str: String de data
            
        Returns:
            datetime: Data convertida ou None
        """
        if not date_str:
            return None
        
        try:
            # Remover timezone info se presente
            if 'T' in date_str:
                date_str = date_str.split('T')[0]
            return datetime.strptime(date_str, '%Y-%m-%d').date()
        except ValueError:
            return None
    
    @staticmethod
    def parse_datetime(datetime_str: Optional[str]) -> Optional[datetime]:
        """
        Converte string de datetime para objeto datetime
        
        Args:
            datetime_str: String de datetime
            
        Returns:
            datetime: Objeto datetime ou None
        """
        if not datetime_str:
            return None
        
        try:
            # Formato da API: "2025-07-15T14:30:00"
            return datetime.fromisoformat(datetime_str.replace('Z', '+00:00'))
        except:
            return None


class ProgressLogger:
    """Logger centralizado para progresso ETL"""
    
    def __init__(self, total_items: int, description: str = "Processando", show_percentage: bool = True):
        """
        Inicializa o logger de progresso
        
        Args:
            total_items: Total de itens a processar
            description: Descri√ß√£o da opera√ß√£o
            show_percentage: Se deve mostrar percentual
        """
        self.total = total_items
        self.current = 0
        self.description = description
        self.show_percentage = show_percentage
        self.start_time = datetime.now()
        
        print(f"üîÑ {self.description}: 0/{self.total}")
    
    def update(self, increment: int = 1, item_description: str = ""):
        """
        Atualiza progresso com logging
        
        Args:
            increment: Incremento no contador
            item_description: Descri√ß√£o do item atual
        """
        self.current += increment
        
        if self.show_percentage:
            percentage = (self.current / self.total) * 100
            print(f"üîÑ {self.description}: {self.current}/{self.total} ({percentage:.1f}%)")
        else:
            print(f"üîÑ {self.description}: {self.current}/{self.total}")
        
        if item_description:
            print(f"   üìÑ {item_description}")
    
    def finish(self, message: str = "Conclu√≠do"):
        """
        Finaliza com resumo
        
        Args:
            message: Mensagem de conclus√£o
        """
        duration = datetime.now() - self.start_time
        print(f"‚úÖ {message}: {self.current}/{self.total} itens")
        print(f"‚è±Ô∏è Dura√ß√£o: {duration.total_seconds():.1f}s")


class DatabaseManager:
    """Gerenciador de opera√ß√µes em lote no banco"""
    
    def __init__(self, db: Session, batch_size: int = 1000):
        """
        Inicializa o gerenciador de banco
        
        Args:
            db: Sess√£o do banco
            batch_size: Tamanho do lote para commits
        """
        self.db = db
        self.batch_size = batch_size
    
    def check_duplicate(self, model_class, unique_field: str, value: Any) -> bool:
        """
        Verifica se registro j√° existe
        
        Args:
            model_class: Classe do modelo
            unique_field: Campo √∫nico
            value: Valor a verificar
            
        Returns:
            bool: True se existe, False caso contr√°rio
        """
        try:
            filter_kwargs = {unique_field: value}
            existing = self.db.query(model_class).filter_by(**filter_kwargs).first()
            return existing is not None
        except Exception as e:
            print(f"‚ùå Erro ao verificar duplicata: {e}")
            return False
    
    def bulk_save(self, objects: List[Any]) -> int:
        """
        Salva objetos em lote com commit autom√°tico
        
        Args:
            objects: Lista de objetos para salvar
            
        Returns:
            int: N√∫mero de objetos salvos
        """
        if not objects:
            return 0
        
        saved_count = 0
        
        try:
            for obj in objects:
                self.db.add(obj)
                saved_count += 1
                
                # Commit em lote
                if saved_count % self.batch_size == 0:
                    self.db.commit()
                    print(f"      üíæ Commit em lote: {saved_count} objetos")
            
            # Commit final
            self.db.commit()
            print(f"      ‚úÖ Commit final: {saved_count} objetos salvos")
            
        except Exception as e:
            print(f"‚ùå Erro ao salvar em lote: {e}")
            self.db.rollback()
            return 0
        
        return saved_count
    
    def safe_commit(self) -> bool:
        """
        Commit seguro com tratamento de erro
        
        Returns:
            bool: True se sucesso, False caso contr√°rio
        """
        try:
            self.db.commit()
            return True
        except Exception as e:
            print(f"‚ùå Erro no commit: {e}")
            self.db.rollback()
            return False


class DataValidator:
    """Validador de dados centralizado"""
    
    @staticmethod
    def validate_required_fields(data: Dict, required_fields: List[str]) -> tuple[bool, List[str]]:
        """
        Valida campos obrigat√≥rios
        
        Args:
            data: Dados a validar
            required_fields: Lista de campos obrigat√≥rios
            
        Returns:
            tuple: (valido, campos_faltando)
        """
        if not data:
            return False, required_fields.copy()
        
        missing_fields = []
        for field in required_fields:
            if field not in data or data[field] is None or data[field] == '':
                missing_fields.append(field)
        
        return len(missing_fields) == 0, missing_fields
    
    @staticmethod
    def sanitize_string(value: Any) -> Optional[str]:
        """
        Sanitiza√ß√£o de strings
        
        Args:
            value: Valor a sanitizar
            
        Returns:
            str: String sanitizada ou None
        """
        if value is None:
            return None
        
        if isinstance(value, str):
            return value.strip()
        
        return str(value).strip()
    
    @staticmethod
    def extract_monetary_value(text: str) -> Optional[float]:
        """
        Extrai valor monet√°rio de texto
        
        Args:
            text: Texto contendo valor monet√°rio
            
        Returns:
            float: Valor extra√≠do ou None
        """
        if not text:
            return None
        
        import re
        
        # Padr√µes para encontrar valores monet√°rios
        padroes = [
            r'R\$[\s]*([\d.,]+)',
            r'valor[\s]*:[\s]*R\$[\s]*([\d.,]+)',
            r'valor[\s]*de[\s]*([\d.,]+)',
            r'([\d.,]+)\s*reais'
        ]
        
        for padrao in padroes:
            match = re.search(padrao, text.lower())
            if match:
                valor_str = match.group(1).replace('.', '').replace(',', '')
                try:
                    return float(valor_str)
                except ValueError:
                    continue
        
        return None


class GCSUploader:
    """Uploader centralizado para GCS"""
    
    def __init__(self):
        """Inicializa o uploader GCS"""
        self.gcs_manager = get_gcs_manager()
        self.available = self.gcs_manager.is_available() if self.gcs_manager else False
        
        if self.available:
            print("‚úÖ GCS Uploader inicializado")
        else:
            print("‚ö†Ô∏è GCS n√£o dispon√≠vel")
    
    def upload_data(self, data: Dict, bucket_path: str, metadata: Dict = None) -> Optional[str]:
        """
        Upload gen√©rico para GCS
        
        Args:
            data: Dados para upload
            bucket_path: Caminho no bucket
            metadata: Metadados adicionais
            
        Returns:
            str: URL do objeto no GCS ou None
        """
        if not self.available:
            return None
        
        try:
            # Adicionar metadados se fornecidos
            if metadata:
                data['_metadata'] = metadata
            
            # Fazer upload usando o m√©todo apropriado baseado no tipo
            if 'proposicao' in bucket_path.lower():
                return self._upload_proposicao(data, bucket_path)
            elif 'emenda' in bucket_path.lower():
                return self._upload_emenda(data, bucket_path)
            else:
                return self._upload_generic(data, bucket_path)
                
        except Exception as e:
            print(f"‚ùå Erro no upload GCS: {e}")
            return None
    
    def _upload_proposicao(self, data: Dict, bucket_path: str) -> Optional[str]:
        """Upload espec√≠fico para proposi√ß√µes"""
        try:
            ano = data.get('ano', datetime.now().year)
            tipo = data.get('tipo', 'UNKNOWN')
            api_id = str(data.get('api_camara_id', 'unknown'))
            
            return self.gcs_manager.upload_proposicao(
                data, ano, tipo, api_id, data.get('texto_completo')
            )
        except Exception as e:
            print(f"‚ùå Erro no upload de proposi√ß√£o: {e}")
            return None
    
    def _upload_emenda(self, data: Dict, bucket_path: str) -> Optional[str]:
        """Upload espec√≠fico para emendas"""
        try:
            ano = data.get('ano', datetime.now().year)
            api_id = str(data.get('api_camara_id', 'unknown'))
            
            return self.gcs_manager.upload_emenda(data, ano, api_id)
        except Exception as e:
            print(f"‚ùå Erro no upload de emenda: {e}")
            return None
    
    def _upload_generic(self, data: Dict, bucket_path: str) -> Optional[str]:
        """Upload gen√©rico"""
        try:
            # Implementar upload gen√©rico se necess√°rio
            return self.gcs_manager.upload_json(data, bucket_path)
        except Exception as e:
            print(f"‚ùå Erro no upload gen√©rico: {e}")
            return None


class HashGenerator:
    """Gerador de hashes para deduplica√ß√£o"""
    
    @staticmethod
    def generate_data_hash(data: Dict) -> str:
        """
        Gera hash MD5 dos dados para deduplica√ß√£o
        
        Args:
            data: Dados para gerar hash
            
        Returns:
            str: Hash MD5
        """
        try:
            # Ordenar dados para consist√™ncia
            ordered_data = json.dumps(data, sort_keys=True, default=str)
            return hashlib.md5(ordered_data.encode()).hexdigest()
        except Exception as e:
            print(f"‚ùå Erro ao gerar hash: {e}")
            return hashlib.md5(str(data).encode()).hexdigest()


class APIRateLimiter:
    """Gerenciador de rate limiting para APIs"""
    
    def __init__(self, delay: float = 1.0):
        """
        Inicializa o rate limiter
        
        Args:
            delay: Delay entre requisi√ß√µes em segundos
        """
        self.delay = delay
        self.last_request = None
    
    def wait_if_needed(self):
        """Aguarda se necess√°rio para respeitar rate limit"""
        if self.last_request:
            elapsed = time.time() - self.last_request
            if elapsed < self.delay:
                sleep_time = self.delay - elapsed
                time.sleep(sleep_time)
        
        self.last_request = time.time()


# Fun√ß√µes utilit√°rias globais para compatibilidade
def create_etl_logger(total_items: int, description: str = "Processando") -> ProgressLogger:
    """
    Factory function para criar logger de progresso
    
    Args:
        total_items: Total de itens
        description: Descri√ß√£o da opera√ß√£o
        
    Returns:
        ProgressLogger: Inst√¢ncia do logger
    """
    return ProgressLogger(total_items, description)


def create_db_manager(db: Session, batch_size: int = 1000) -> DatabaseManager:
    """
    Factory function para criar gerenciador de banco
    
    Args:
        db: Sess√£o do banco
        batch_size: Tamanho do lote
        
    Returns:
        DatabaseManager: Inst√¢ncia do gerenciador
    """
    return DatabaseManager(db, batch_size)


def create_gcs_uploader() -> GCSUploader:
    """
    Factory function para criar uploader GCS
    
    Returns:
        GCSUploader: Inst√¢ncia do uploader
    """
    return GCSUploader()


# Classe de exce√ß√£o personalizada para ETL
class ETLException(Exception):
    """Exce√ß√£o base para opera√ß√µes ETL"""
    pass


class APIException(ETLException):
    """Exce√ß√£o para erros de API"""
    pass


class DatabaseException(ETLException):
    """Exce√ß√£o para erros de banco"""
    pass


class ValidationException(ETLException):
    """Exce√ß√£o para erros de valida√ß√£o"""
    pass
